# ğŸ¤– Chatbot Intelligent IA - Gestion de Projets d'Entreprise

Un assistant conversationnel intelligent basÃ© sur l'IA utilisant Rasa Pro CALM pour la **prÃ©diction des compÃ©tences**, l'**Ã©valuation des risques** et l'**estimation des coÃ»ts** de projets en entreprise.

## ğŸ¯ FonctionnalitÃ©s Principales

- ğŸ§  **PrÃ©diction des CompÃ©tences** - Analyse et recommande les compÃ©tences nÃ©cessaires pour les projets
- âš ï¸ **Ã‰valuation des Risques** - Identifie et Ã©value les risques potentiels des projets
- ğŸ’° **Estimation des CoÃ»ts** - Calcule les coÃ»ts prÃ©visionnels basÃ©s sur l'analyse IA
- ğŸ”„ **Architecture CALM** - Conversations contextuelles avec logique mÃ©tier structurÃ©e
- ğŸ¤ **Reconnaissance Vocale** - IntÃ©gration Google Cloud Speech-to-Text
- ğŸ”Š **SynthÃ¨se Vocale** - RÃ©ponses audio avec Google Cloud Text-to-Speech
- ğŸ¤– **IA GÃ©nÃ©rative** - Powered by Google Gemini AI
- ğŸ“Š **Analyse Vectorielle** - Recherche sÃ©mantique avec FAISS
- ğŸŒ **Interface Web** - Frontend Flask avec support multi-canal

## ğŸ—ï¸ Architecture Technique

### Backend
- **Rasa Pro CALM** - Gestionnaire de conversations
- **Flask** - Serveur web et API REST
- **Google Gemini AI** - ModÃ¨le de langage pour l'analyse intelligente
- **Google Cloud Speech Services** - STT/TTS
- **FAISS** - Recherche vectorielle pour la similaritÃ© sÃ©mantique
- **NLTK** - Traitement du langage naturel

### Frontend
- **JavaScript** - Interface utilisateur interactive
- **CORS** - Support multi-domaines

## ğŸ“‹ PrÃ©requis

- Python 3.8+
- Licence Rasa Pro
- Google Cloud Account (Speech Services)
- Gemini API Key
- Node.js (pour le frontend)

## ğŸš€ Installation

### 1. Cloner le Repository
```bash
git clone https://github.com/votre-username/chatbot-ia-projets.git
cd chatbot-ia-projets
```

### 2. Environnement Virtuel
```bash
python -m venv venv
source venv/bin/activate  # Windows: venv\Scripts\activate
```

### 3. Installer les DÃ©pendances
```bash
pip install -r requirements.txt
```

### 4. Configuration des Variables d'Environnement
```bash
cp .env.example .env
# Ã‰diter .env avec vos clÃ©s API rÃ©elles
```

### 5. Configuration Google Cloud
```bash
# Configurez vos credentials Google Cloud
export GOOGLE_APPLICATION_CREDENTIALS="path/to/your/credentials.json"
```

### 6. Initialiser NLTK
```bash
python -c "import nltk; nltk.download('stopwords'); nltk.download('wordnet')"
```

### 7. EntraÃ®ner le ModÃ¨le
```bash
rasa train
```

## âš™ï¸ Configuration

### Variables d'Environnement

Copiez `.env.example` vers `.env` et configurez :

```bash
# IA et APIs
GEMINI_API_KEY=votre_cle_gemini_api
GOOGLE_APPLICATION_CREDENTIALS=path/to/google-credentials.json

# Rasa Pro
RASA_PRO_LICENSE=votre_licence_rasa_pro

# Base de donnÃ©es
DATABASE_URL=postgresql://user:password@localhost:5432/rasa_pro

# Serveurs
RASA_SERVER_URL=http://localhost:5005
ACTION_SERVER_URL=http://localhost:5055
FLASK_SERVER_URL=http://localhost:8000

# Environnement
ENVIRONMENT=development
DEBUG=true
LOG_LEVEL=INFO
```

### Architecture CALM

#### Flows (`data/flows.yml`)
Contient les flux de conversation pour :
- Analyse de compÃ©tences projet
- Ã‰valuation des risques
- Estimation des coÃ»ts
- Recommandations personnalisÃ©es

#### Patterns (`data/patterns.yml`)
DÃ©finit les patterns pour reconnaÃ®tre :
- Demandes d'analyse de compÃ©tences
- Questions sur les risques
- RequÃªtes d'estimation de coÃ»ts

#### Prompts (`prompts/`)
Prompts LLM pour guider :
- L'analyse intelligente des projets
- La gÃ©nÃ©ration de recommandations
- L'Ã©valuation contextuelle

## ğŸ”§ Structure du Projet

```
â”œâ”€â”€ __init__.py              # Initialisation du package
â”œâ”€â”€ actions.py               # Actions personnalisÃ©es avec IA
â”œâ”€â”€ backend.py               # Serveur Flask + APIs
â”œâ”€â”€ app.js                   # Interface utilisateur
â”œâ”€â”€ data/                    # DonnÃ©es d'entraÃ®nement CALM
â”‚   â”œâ”€â”€ flows.yml           # Flux de conversation mÃ©tier
â”‚   â””â”€â”€ patterns.yml        # Patterns de reconnaissance
â”œâ”€â”€ prompts/                 # Prompts pour l'IA gÃ©nÃ©rative
â”œâ”€â”€ static_audio/            # Fichiers audio pour les rÃ©ponses
â”œâ”€â”€ models/                  # ModÃ¨les entraÃ®nÃ©s (gitignored)
â”œâ”€â”€ .env                     # Variables d'environnement (gitignored)
â”œâ”€â”€ config.yml               # Configuration Rasa avec FlowPolicy
â”œâ”€â”€ domain.yml               # Domaine de l'assistant
â”œâ”€â”€ credentials.yml          # Identifiants des canaux
â””â”€â”€ endpoints.yml            # Points de terminaison externes
```

## ğŸƒâ€â™‚ï¸ Utilisation

### Mode DÃ©veloppement

```bash
# Terminal 1: Action Server
rasa run actions --debug

# Terminal 2: Rasa Server
rasa run --enable-api --cors "*" --debug

# Terminal 3: Backend Flask
python backend.py

# Terminal 4: Test en ligne de commande
rasa shell
```

### Mode Production

```bash
# DÃ©marrer tous les services
rasa run --enable-api --cors "*" --port 5005 &
rasa run actions --port 5055 &
python backend.py &
```

## ğŸ§ª Cas d'Usage

### 1. PrÃ©diction des CompÃ©tences
```
Utilisateur: "Quelles compÃ©tences sont nÃ©cessaires pour un projet de dÃ©veloppement mobile ?"
Bot: Analyse le projet et recommande les compÃ©tences techniques et soft skills
```

### 2. Ã‰valuation des Risques
```
Utilisateur: "Quels sont les risques pour ce projet de transformation digitale ?"
Bot: Identifie les risques techniques, financiers, temporels et humains
```

### 3. Estimation des CoÃ»ts
```
Utilisateur: "Combien coÃ»terait le dÃ©veloppement d'une plateforme e-commerce ?"
Bot: Calcule une estimation basÃ©e sur les paramÃ¨tres du projet
```

## ğŸ³ DÃ©ploiement Docker

### Dockerfile
```dockerfile
FROM rasa/rasa:3.6.0-full

WORKDIR /app
COPY requirements.txt .
RUN pip install -r requirements.txt

COPY . .

EXPOSE 5005 5055 8000
CMD ["run", "--enable-api", "--cors", "*"]
```

### Docker Compose
```yaml
version: '3.8'
services:
  rasa:
    build: .
    ports:
      - "5005:5005"
    environment:
      - GEMINI_API_KEY=${GEMINI_API_KEY}
  
  actions:
    build: .
    ports:
      - "5055:5055"
    command: ["run", "actions"]
  
  backend:
    build: .
    ports:
      - "8000:8000"
    command: ["python", "backend.py"]
```

## ğŸ“Š APIs Disponibles

### Rasa API
- `POST /webhooks/rest/webhook` - Envoyer des messages
- `GET /model` - Informations sur le modÃ¨le

### Flask Backend
- `POST /api/chat` - Interface de chat
- `POST /api/voice` - Traitement vocal
- `GET /api/projects` - Analyse de projets
- `POST /api/skills/predict` - PrÃ©diction de compÃ©tences
- `POST /api/risks/evaluate` - Ã‰valuation de risques
- `POST /api/costs/estimate` - Estimation de coÃ»ts

## ğŸ” DÃ©pannage

### ProblÃ¨mes Courants

**Erreur "Model not found":**
```bash
rasa train --force
```

**Erreur Google Cloud:**
```bash
export GOOGLE_APPLICATION_CREDENTIALS="path/to/credentials.json"
gcloud auth application-default login
```

**Erreur Gemini API:**
```bash
# VÃ©rifiez votre clÃ© API dans .env
# Assurez-vous que l'API Gemini est activÃ©e
```

**Erreur FAISS:**
```bash
pip install faiss-cpu  # ou faiss-gpu pour GPU
```

**Erreur NLTK:**
```bash
python -c "import nltk; nltk.download('all')"
```

## ğŸ¤ Contribution

1. Fork le repository
2. CrÃ©er une branche feature (`git checkout -b feature/nouvelle-fonctionnalite`)
3. Commit les changements (`git commit -m 'Ajout nouvelle fonctionnalitÃ©'`)
4. Push la branche (`git push origin feature/nouvelle-fonctionnalite`)
5. Ouvrir une Pull Request

## ğŸ“ Licence

Ce projet est sous licence - voir le fichier LICENSE pour plus de dÃ©tails.

## ğŸ¢ Cas d'Usage Entreprise

- **Consultation de Projets** - Analyse prÃ©liminaire des besoins projet
- **Gestion des Ressources** - Optimisation de l'allocation des compÃ©tences
- **ContrÃ´le des Risques** - Identification proactive des problÃ¨mes potentiels
- **BudgÃ©tisation Intelligente** - Estimation prÃ©cise des coÃ»ts projet
- **Support DÃ©cisionnel** - Aide Ã  la prise de dÃ©cision stratÃ©gique

## ğŸ“ Support

Pour le support technique, crÃ©ez une issue dans ce repository ou contactez [mohamedamineazouzi49@gmail.com]
